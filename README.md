# ğŸ SnakeGame AI â€“ Deep Q-Learning avec Obstacles Dynamiques

Un projet de jeu Snake contrÃ´lÃ© par une intelligence artificielle utilisant le Deep Q-Learning (DQN). Le serpent apprend Ã  survivre, Ã  manger, et Ã  Ã©viter des obstacles gÃ©nÃ©rÃ©s alÃ©atoirement sur le terrain.

---

## ğŸ“Œ Objectifs du projet

- ImplÃ©menter une **IA basÃ©e sur l'apprentissage par renforcement** pour le jeu Snake.
- Ajouter une **gÃ©nÃ©ration dynamique d'obstacles** : carrÃ©s et rectangles placÃ©s alÃ©atoirement Ã  chaque partie.
- EmpÃªcher l'IA de rester coincÃ©e dans des **boucles de mouvement**.
- Tester la **robustesse du modÃ¨le** dans des environnements variÃ©s.

---

## ğŸ§  Technologies utilisÃ©es

- `Python` + `Pygame` : pour crÃ©er lâ€™environnement de jeu.
- `PyTorch` : pour le modÃ¨le de Deep Q-Learning.
- `Numpy` : pour les manipulations de donnÃ©es.
- `Matplotlib` (optionnel) : pour la visualisation des performances.

---

## ğŸ® Fonctionnement

### âš™ï¸ 1. Environnement (`game.py`)  Ã  changer da
- GÃ©nÃ¨re un terrain avec :
  - 3 **carrÃ©s** (taille fixe)  
  - 2 **rectangles** (taille fixe)  
- EmpÃªche la nourriture et les obstacles de se chevaucher ou dâ€™apparaÃ®tre au centre.

### ğŸ§  2. ModÃ¨le d'IA (`model.py`)
- RÃ©seau simple : `Linear_QNet` (entrÃ©e 11 â†’ 256 â†’ sortie 3).
- Trois actions possibles : `gauche`, `droite`, `tout droit`.

### ğŸ” 3. EntraÃ®nement (`agent.py`)
- Apprentissage par renforcement basÃ© sur la fonction de Bellman.
- RÃ©compense +10 pour manger, -10 pour collision, -0.1 par pas pour encourager l'efficacitÃ©.

### ğŸ§ª 4. Ã‰valuation (`testModel.py`)
- Lâ€™IA joue automatiquement plusieurs parties et affiche le score.
- IntÃ¨gre une **composante alÃ©atoire** dans les mouvements (ex: 10%) pour amÃ©liorer lâ€™exploration.

---

## ğŸ§  ReprÃ©sentation de l'Ã©tat (entrÃ©e du modÃ¨le)

| Ã‰tat | Description |
|------|-------------|
| Danger devant, gauche, droite | BoolÃ©ens |
| Direction actuelle | 4 directions encodÃ©es |
| Position de la nourriture | Haut / Bas / Gauche / Droite par rapport Ã  la tÃªte |

---

## ğŸ’¡ AmÃ©liorations intÃ©grÃ©es

âœ… Boucles dÃ©tectÃ©es et pÃ©nalisÃ©es  
âœ… Mouvement alternatif intelligent si collision imminente  
âœ… Obstacles alÃ©atoires Ã  chaque partie  
âœ… ProbabilitÃ© configurable de mouvements alÃ©atoires

---

## ğŸ“ˆ RÃ©sultats

- Lâ€™agent apprend efficacement dans un environnement sans et avec obstacles.
- Le modÃ¨le reste robuste mÃªme avec des obstacles dynamiques.
- RÃ©duction significative des parties bloquÃ©es en boucle.

---

## ğŸš€ Lancer le projet

```bash
git clone https://github.com/ton-pseudo/SnakeGame-AI.git
cd SnakeGame-AI
pip install torch pygame numpy
python agent3.py     # Pour entraÃ®ner le modÃ¨le
python testModel2.py # Pour tester un modÃ¨le existant
